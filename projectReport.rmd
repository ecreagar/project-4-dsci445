---
title: 'xYAF: A metric to evaluate punt returns in the NFL'
author: "Ethan, Kilbourne, Michael"
date: "12/7/2021"
output:
  slidy_presentation: default
  ioslides_presentation: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(GGally)
library(ISLR)
library(caret)
library(MASS)
library(class)
library(knitr)
library(leaps)
library(glmnet)
library(boot)
library(gam)
library(tree)
library(gbm)
library(randomForest)
library(e1071)

```

## Background - "Expected" metrics

- In sports analytics, "expected" metrics are used to evaluate player or team performance
  - Soccer: Expected goals (xG) $^{[1]}$, expected assists, expected points
  - Basketball: Expected points, expected possession value $^{[2]}$
  - Football: Expected Yards after Catch $^{[3]}$
  
- Many uses for these metrics
  - Compare a player's output to an objective baseline
  - Evaluate a team's performance by eliminating randomness
  
## Expected Yards After Fielding (xYAF)

- Given the current conditions when fielding a punt, how many yards do we expect the punt returner to gain

- Takes into account
  - Punt position
  - Fielding position
  - All defender positions (relative)
  - Punt hang time
  
- Should return an accurate estimate of how many yards the player gains based on these factors

## Data

- NFL 2022 Big Data Bowl
  - "The annual sports analytics contest from NFL Football Operations challenges members of the analytics community to contribute to the NFLâ€™s continuing evolution of the use of advanced analytics."
  - Last year's winner: "A Defensive Player Coverage Evaluation Framework"$^{[3]}$
  - This year, focuses on Special Teams Plays
  - Contains 19,979 plays from 2018 to 2020
  
- After filtering, we predict based on ~2000 returned punts


# Model Evaluations

## Linear Regression

![](Images/QQLM.png){width=80%}

## Linear Regression

![](Images/LMMod1.png){width=80%}
![](Images/LMMod2.png){width=80%}
![](Images/LMMod3.png){width=80%}

## Linear Regression

![](Images/ResidualsFittedLM.png){width=80%}


## Logistic Regression

![](Images/LogitMod1.png){width=80%}
![](Images/LogitMod2.png){width=80%}
![](Images/LogitMod3.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Forward Subset Selection](Images/AdjR2Forward.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Forward Variable Selection](Images/ForwardVariables.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Forward Variable Selection](Images/ForwardVars.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Backward](Images/AdjR2Backward.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Backward Variable Selection](Images/BackwardVariables.png){width=80%}

## Best Subset Selection (Forward, Backward)

![Backward Variable Selection](Images/BackwardVars.png){width=80%}

## Random Forests

![](Images/Tree.png){width=80%}

## Random Forests

![](Images/ActPredForest.png){width=80%}

## Random Forests

![](Images/ForestMod.png){width=80%}

## LASSO/Ridge Regression

![Actual vs Predicted Lasso](Images/ActPredLasso.png){width=80%}

## GAMs

![GAM Model](Images/GAMMod.png){width=60%}

## GAM

![Actual vs Predicted](Images/ActPredGam.png){width=80%}

## Splines

![Actual vs Predicted](Images/ActPredSpline.png){width=80%}

## Boosting

![Actual vs Predicted](Images/ActPredBoost.png){width=80%}

## Model Comparison

![MSEs](Images/ModelComparison.png)

# Evaluation and Conclusion

## Evaluation

Problem: Some methods assume normally distributed data

```{r, echo = FALSE, message = FALSE}
data = read.csv("Data/puntinfo.csv")
n <- ggplot(data = data, aes(x = yards_gained, fill = ..x..)) + 
  geom_histogram(bins=100) + 
  scale_fill_gradient2(low='darkblue', mid='blue', high='lightblue', midpoint=-5, name = 'Yards Gained')

suppressWarnings(print(n))
```

## Evaluation

Possible solution: Variable Transforms

```{r, echo = FALSE, message = FALSE}
l <- ggplot(data = data, aes(x = log(yards_gained), fill = ..x..)) + 
  geom_histogram(bins=100) + 
  scale_fill_gradient2(low='darkblue', mid='blue', high='lightblue', midpoint=0, name = 'Yards Gained')

suppressWarnings(print(l))
```

## Evaluation


```{r, echo = FALSE, message=FALSE}
l <- ggplot(data = data, aes(x = sqrt(yards_gained), fill = ..x..)) + 
  geom_histogram(bins=100) + 
  scale_fill_gradient2(low='darkblue', mid='blue', high='lightblue', midpoint=0, name = 'Yards Gained')

suppressWarnings(print(l))
```

Better, but also doesn't handle negative values.

## Examples

![An 85 yard punt return by Diontae Johnson](https://media.giphy.com/media/eelOXCc4Xj3QuVP9mz/giphy-downsized-large.gif)
Predicted: 4.78 yards

## Examples

![A 2 yard punt return by Richie James Jr.](https://media.giphy.com/media/HdE4nMCU1kqKJm3cX6/giphy-downsized-large.gif)
Predicted: 1.52 yards

## Works Cited

[1] Sam Green. Assessing the performance of Premier League goalscorers. Stats Perform, 2012.

[2] https://grantland.com/features/expected-value-possession-nba-analytics/

[3] https://www.nfl.com/news/next-gen-stats-intro-to-expected-yards-after-catch-0ap3000000983644

[4] Peng et. al., A Defensive Player Coverage Evaluation Framework, https://www.kaggle.com/model284/a-defensive-player-coverage-evaluation-framework
